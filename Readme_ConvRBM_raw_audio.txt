Readme file for auditory filterbank learning using ConvRBM (in MATLAB)

The main file is hardik_raw_train.m, that will guide you to train the ConvRBM.

The code is developed by Hardik B. Sailor from the initial ConvRBM code developed by H. Lee for spectrograms. 

Earlier ConvRBM was developed to learn receptive fields from spectrograms in following paper: 

Honglak Lee, Yan Largman, Peter Pham, and Andrew Y. Ng, "Unsupervised feature learning for audio classification using convolutional deep belief networks", Advances in Neural Information Processing Systems (NIPS) 22, 2009.

We have developed it to learn auditory filterbank from the variable length raw speech and audio signals. We also used Noisy ReLU for inference, annealing dropout and Adam optimization. Following are our publications from this codes. Please cite our IEEE Journal paper if you use this codes.

Journal Publications

1. Hardik B. Sailor and Hemant A. Patil, "Auditory feature representation using convolutional restricted Boltzmann machine and Teager energy operator for speech recognition", The Journal of the Acoustical Society of America Express Letters (JASA-EL), Volume: 141, Issue: 6, June 2017.

2. Hardik B. Sailor and Hemant A. Patil, "Novel unsupervised auditory filterbank  learning using convolutional RBM for  speech recognition,"  in IEEE/ACM Transactions on Audio, Speech and Language Processing (IEEE TASLP), Volume: 24, Issue: 12, Page(s): 2341 - 2353, December 2016. IEEE Xplore link. (Detailed and extended version of our ICASSP 2016 paper ) 

Conference Publications

1. Hardik B. Sailor, "Auditory Representation Learning", accepted in FOURTH DOCTORAL CONSORTIUM at INTERSPEECH 2018, Hyderabad, India.

2. Hardik B. Sailor and Hemant A. Patil, "Neural Networks-based Automatic Speech Recognition for Agricultural Commodity in Gujarati Language," accepted in 6th Int. Workshop on Spoken Language Technologies for Under-resourced Languages(SLTU) (Satellite event of INTERSPEECH 2018), Gurugram, India on 29-31 August 2018.

3. Hardik B. Sailor, Maddala Venkata Siva Krishna, Diksha Chhabra, Ankur Patil, Madhu Kamble and Hemant Patil, "DA-IICT/IIITV System for Low Resource Speech Recognition Challenge 2018" accepted in INTERSPEECH 2018, Hyderabad, India, September 2018 (Received ISCA grant). 

4. Hardik B. Sailor, Madhu Kamble and Hemant Patil, "Auditory Filterbank Learning for Temporal Modulation Features in Replay Spoof Speech Detection", accepted in INTERSPEECH 2018, Hyderabad, India, September 2018 (Received ISCA grant). 

5. Hardik B. Sailor and Hemant A. Patil, "Auditory Filterbank Learning Using ConvRBM for Infant Cry Classification",accepted in INTERSPEECH 2018, Hyderabad, India, September 2018 (Received ISCA grant).

6. Hardik B. Sailor, Dharmesh Agrawal and Hemant A. Patil,"Unsupervised Filterbank Learning Using Convolutional Restricted Boltzmann Machine for Environmental Sound Classification," in INTERSPEECH 2017, Stockholm, Sweden, August 20-24, 2017.

7. Hardik B. Sailor, Madhu Kamble and Hemant A. Patil, "Unsupervised Representation Learning Using Convolutional Restricted Boltzmann Machine for Spoof Speech Detection," in INTERSPEECH 2017, Stockholm,  Sweden, August 20-24, 2017.

 
8. Hardik B. Sailor and Hemant A. Patil, "Unsupervised Deep Auditory Model Using Stack of Convolutional RBMs For Speech Recognition", accepted in INTERSPEECH 2016, San Francisco, California.

9. Hardik B. Sailor and Hemant A. Patil, “Filterbank Learning Using Convolutional Restricted Boltzmann Machine For Speech Recognition”, in Proc. Int. Conf. Acoust., Speech and Signal Process., (ICASSP) 2016, Shanghai, China.